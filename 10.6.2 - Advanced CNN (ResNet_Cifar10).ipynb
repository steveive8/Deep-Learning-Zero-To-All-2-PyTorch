{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lab 10.6.2: Advanced CNN (Resnet with CIFAR10)\r\n",
    "\r\n",
    "Edited By Steve Ive\r\n",
    "\r\n",
    "Reference from\r\n",
    "\r\n",
    "https://github.com/deeplearningzerotoall/PyTorch/blob/master/lab-10_6_2_Advance-CNN(ResNet_cifar10).ipynb"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "import torchvision\r\n",
    "import torchvision.datasets as datasets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "\r\n",
    "import visdom"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "\r\n",
    "torch.manual_seed(1)\r\n",
    "\r\n",
    "if device == 'cuda':\r\n",
    "    torch.cuda.manual_seed_all(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "vis = visdom.Visdom()\r\n",
    "vis.close(env = \"main\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\connection.py\", line 169, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\util\\connection.py\", line 96, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\util\\connection.py\", line 86, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\connectionpool.py\", line 394, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\connection.py\", line 234, in request\n",
      "    super(HTTPConnection, self).request(method, url, body=body, headers=headers)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\http\\client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\http\\client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\http\\client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\http\\client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\http\\client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\connection.py\", line 200, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\connection.py\", line 181, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000024D2556BA30>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\util\\retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000024D2556BA30>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\visdom\\__init__.py\", line 708, in _send\n",
      "    return self._handle_post(\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\requests\\sessions.py\", line 590, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\requests\\sessions.py\", line 542, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\requests\\sessions.py\", line 655, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000024D2556BA30>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "[WinError 10061] No connection could be made because the target machine actively refused it\n",
      "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\connection.py\", line 169, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\util\\connection.py\", line 96, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\util\\connection.py\", line 86, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\connectionpool.py\", line 394, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\connection.py\", line 234, in request\n",
      "    super(HTTPConnection, self).request(method, url, body=body, headers=headers)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\http\\client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\http\\client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\http\\client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\http\\client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\http\\client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\connection.py\", line 200, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\connection.py\", line 181, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000024D2559A670>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\urllib3\\util\\retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /close (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000024D2559A670>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\visdom\\__init__.py\", line 708, in _send\n",
      "    return self._handle_post(\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\requests\\sessions.py\", line 590, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\requests\\sessions.py\", line 542, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\requests\\sessions.py\", line 655, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /close (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000024D2559A670>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Value Tracker"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def value_tracker(value_plot, value, index):\r\n",
    "    '''num, loss_value are Tensor'''\r\n",
    "    vis.line(X = index, Y = value, win = value_plot, update = 'append')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\r\n",
    "\r\n",
    "### How to Calculate mean and std in Normalize"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "transform = transforms.Compose([\r\n",
    "    transforms.ToTensor()\r\n",
    "])\r\n",
    "\r\n",
    "trainset = datasets.CIFAR10(root = 'cifar10/', download = True, transform = transform, train = True)\r\n",
    "\r\n",
    "print(trainset.data.shape)\r\n",
    "\r\n",
    "train_data_mean = trainset.data.mean(axis = (0, 1, 2))\r\n",
    "train_data_std = trainset.data.std(axis = (0, 1, 2))\r\n",
    "\r\n",
    "print(train_data_mean)\r\n",
    "print(train_data_std)\r\n",
    "\r\n",
    "train_data_mean = train_data_mean / 255\r\n",
    "train_data_std = train_data_std / 255\r\n",
    "\r\n",
    "print(train_data_mean)\r\n",
    "print(train_data_std)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3)\n",
      "[125.30691805 122.95039414 113.86538318]\n",
      "[62.99321928 62.08870764 66.70489964]\n",
      "[0.49139968 0.48215841 0.44653091]\n",
      "[0.24703223 0.24348513 0.26158784]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "transform_train = transforms.Compose([\r\n",
    "    transforms.ToTensor(),\r\n",
    "    transforms.Normalize(train_data_mean, train_data_std)\r\n",
    "])\r\n",
    "\r\n",
    "transform_test = transforms.Compose([\r\n",
    "    transforms.ToTensor(),\r\n",
    "    transforms.Normalize(train_data_mean, train_data_std)\r\n",
    "])\r\n",
    "\r\n",
    "trainset = datasets.CIFAR10(download = True, root = 'cifar10/', transform = transform_train, train = True)\r\n",
    "testset = datasets.CIFAR10(download = True, root = 'cifar10/', transform = transform_test, train = False)\r\n",
    "\r\n",
    "train_loader = torch.utils.data.DataLoader(dataset = trainset, batch_size = 256, shuffle = True, num_workers = 0)\r\n",
    "test_loader = torch.utils.data.DataLoader(dataset = testset, batch_size = 256, shuffle = True, num_workers = 0)\r\n",
    "\r\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horese', 'ship', 'truck')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reform the ResNet since the dataset resolution is too small"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import torchvision.models.resnet as resnet\r\n",
    "from torch import Tensor\r\n",
    "from typing import Type, Any, Callable, Union, List, Optional\r\n",
    "BasicBlock = resnet.BasicBlock\r\n",
    "Bottleneck = resnet.Bottleneck\r\n",
    "conv1x1 = resnet.conv1x1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class ResNet(nn.Module):\r\n",
    "    \r\n",
    "    def __init__(\r\n",
    "        self,\r\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\r\n",
    "        layers: List[int],\r\n",
    "        num_classes: int = 1000,\r\n",
    "        zero_init_residual: bool = False,\r\n",
    "        groups: int = 1,\r\n",
    "        width_per_group: int = 64,\r\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\r\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\r\n",
    "    ) -> None:\r\n",
    "        super(ResNet, self).__init__()\r\n",
    "        if norm_layer is None:\r\n",
    "            norm_layer = nn.BatchNorm2d\r\n",
    "        self._norm_layer = norm_layer\r\n",
    "\r\n",
    "        self.inplanes = 64\r\n",
    "        self.dilation = 1\r\n",
    "        if replace_stride_with_dilation is None:\r\n",
    "            # each element in the tuple indicates if we should replace\r\n",
    "            # the 2x2 stride with a dilated convolution instead\r\n",
    "            replace_stride_with_dilation = [False, False, False]\r\n",
    "        if len(replace_stride_with_dilation) != 3:\r\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\r\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\r\n",
    "        self.groups = groups\r\n",
    "        self.base_width = width_per_group\r\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\r\n",
    "                               bias=False)\r\n",
    "        self.bn1 = norm_layer(self.inplanes)\r\n",
    "        self.relu = nn.ReLU(inplace=True)\r\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "        #change strides from 2 to 1 below -----------------------------\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=1,\r\n",
    "                                       dilate=replace_stride_with_dilation[0])\r\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=1,\r\n",
    "                                       dilate=replace_stride_with_dilation[1])\r\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\r\n",
    "                                       dilate=replace_stride_with_dilation[2])\r\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "        \r\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\r\n",
    "\r\n",
    "        for m in self.modules():\r\n",
    "            if isinstance(m, nn.Conv2d):\r\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\r\n",
    "                nn.init.constant_(m.weight, 1)\r\n",
    "                nn.init.constant_(m.bias, 0)\r\n",
    "\r\n",
    "        # Zero-initialize the last BN in each residual branch,\r\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\r\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\r\n",
    "        if zero_init_residual:\r\n",
    "            for m in self.modules():\r\n",
    "                if isinstance(m, Bottleneck):\r\n",
    "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\r\n",
    "                elif isinstance(m, BasicBlock):\r\n",
    "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\r\n",
    "\r\n",
    "    def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int,\r\n",
    "                    stride: int = 1, dilate: bool = False) -> nn.Sequential:\r\n",
    "        norm_layer = self._norm_layer\r\n",
    "        downsample = None\r\n",
    "        previous_dilation = self.dilation\r\n",
    "        if dilate:\r\n",
    "            self.dilation *= stride\r\n",
    "            stride = 1\r\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\r\n",
    "            downsample = nn.Sequential(\r\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\r\n",
    "                norm_layer(planes * block.expansion),\r\n",
    "            )\r\n",
    "\r\n",
    "        layers = []\r\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\r\n",
    "                            self.base_width, previous_dilation, norm_layer))\r\n",
    "        self.inplanes = planes * block.expansion\r\n",
    "        for _ in range(1, blocks):\r\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\r\n",
    "                                base_width=self.base_width, dilation=self.dilation,\r\n",
    "                                norm_layer=norm_layer))\r\n",
    "\r\n",
    "        return nn.Sequential(*layers)\r\n",
    "\r\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\r\n",
    "        # See note [TorchScript super()]\r\n",
    "        x = self.conv1(x)\r\n",
    "        x = self.bn1(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.maxpool(x)\r\n",
    "\r\n",
    "        x = self.layer1(x)\r\n",
    "        x = self.layer2(x)\r\n",
    "        x = self.layer3(x)\r\n",
    "        x = self.layer4(x)\r\n",
    "\r\n",
    "        x = self.avgpool(x)\r\n",
    "        x = torch.flatten(x, 1)\r\n",
    "        x = self.fc(x)\r\n",
    "\r\n",
    "        return x\r\n",
    "\r\n",
    "    def forward(self, x: Tensor) -> Tensor:\r\n",
    "        return self._forward_impl(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "resnet50 = ResNet(resnet.Bottleneck, [3, 4, 6, 3], 10, True).to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Take a Moment!!!!!!!!!!!!!!!!!\r\n",
    "\r\n",
    "if not normalize the Tensor just like ```torch.Tensor(1, 3, 32, 32).to(device)```\r\n",
    "\r\n",
    "it returns nan to all of classes\r\n",
    "\r\n",
    "**It is important to normalize our data**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "test = torch.rand(1, 3, 32, 32).to(device)\r\n",
    "out = resnet50(test)\r\n",
    "print(out)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.2347, -0.2441,  0.2715,  0.1799,  0.0963, -0.1991,  0.0620, -0.3722,\n",
      "          0.0864,  0.4435]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "optimizer = optim.Adam(resnet50.parameters(), lr = 0.1, weight_decay = 5e-4)\r\n",
    "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size =10, gamma = 0.5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make Plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "loss_plt = vis.line(Y=torch.Tensor(1).zero_(), opts = dict(title = \"loss_tracker\", legend = ['loss'], showlegend = True))\r\n",
    "acc_plt = vis.line(Y = torch.Tensor(1).zero_(), opts = dict(title = 'Accuracy', legend = ['Acc'], showlegend = True))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Acc_check Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def acc_check(net, test_loader, epoch, save = 1):\r\n",
    "    correct = 0\r\n",
    "    total = 0\r\n",
    "    with torch.no_grad():\r\n",
    "        for X, Y in test_loader:\r\n",
    "            X = X.to(device)\r\n",
    "            Y = Y.to(device)\r\n",
    "\r\n",
    "            #prediction\r\n",
    "            pred = net(X)\r\n",
    "\r\n",
    "            _, predicted = torch.max(pred, 1)\r\n",
    "\r\n",
    "            total += Y.size(0)\r\n",
    "            correct += (predicted == Y).sum().item()\r\n",
    "\r\n",
    "    acc = (100 * correct / total)\r\n",
    "    print('Accuracy of the network on the 10000 test images: {}'.format(acc))\r\n",
    "\r\n",
    "    if epoch % 10 == 0:\r\n",
    "        if save:\r\n",
    "            torch.save(net.state_dict(), \"./models/resnet_cifar10/model_epoch_{}_acc_{}.pth\".format(epoch, acc))\r\n",
    "\r\n",
    "    return acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "acc_check(resnet50, test_loader, 1, 0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the network on the 10000 test images: 12.38\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12.38"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training with (acc check + model save)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "print(len(train_loader))\r\n",
    "epochs = 100\r\n",
    "\r\n",
    "for epoch in range(epochs):\r\n",
    "\r\n",
    "    running_loss = 0.0\r\n",
    "    lr_sche.step()\r\n",
    "    \r\n",
    "    for i, data in enumerate(train_loader):\r\n",
    "        #get the inputs\r\n",
    "        X, Y = data\r\n",
    "        X = X.to(device)\r\n",
    "        Y = Y.to(device)\r\n",
    "\r\n",
    "        # zero the parameter gradients\r\n",
    "        optimizer.zero_grad()\r\n",
    "\r\n",
    "        # forward + backward + optimize\r\n",
    "        pred = resnet50(X)\r\n",
    "        \r\n",
    "        #cost\r\n",
    "        cost = F.cross_entropy(pred, Y)\r\n",
    "        \r\n",
    "        #reduce the cost\r\n",
    "        cost.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        #print statistics\r\n",
    "        running_loss += cost.item()\r\n",
    "        if i % 30 == 29:\r\n",
    "            value_tracker(loss_plt, torch.Tensor([running_loss / 30]), torch.Tensor([i + epoch * len(train_loader)]))\r\n",
    "\r\n",
    "    #Check accuracy\r\n",
    "    acc = acc_check(resnet50, test_loader, epoch, save = 1)\r\n",
    "    value_tracker(acc_plt, torch.Tensor([acc]), torch.Tensor([epoch]))\r\n",
    "\r\n",
    "\r\n",
    "print('Finshed Learning')\r\n",
    "            "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "196\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 6.00 GiB total capacity; 3.54 GiB already allocated; 0 bytes free; 3.90 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-78b01fed1f85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m#reduce the cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mcost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 6.00 GiB total capacity; 3.54 GiB already allocated; 0 bytes free; 3.90 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('buddhalight': conda)"
  },
  "interpreter": {
   "hash": "38ed4d61829b01de31b0fe0651719916120d9f7e023a62cbbfea93b7d24a50a0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}