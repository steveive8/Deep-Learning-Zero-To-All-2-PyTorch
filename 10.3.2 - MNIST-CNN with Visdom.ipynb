{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lab 10.3.2 MNIST-CNN with Visdom\r\n",
    "\r\n",
    "Edited By Steve Ive\r\n",
    "\r\n",
    "Here we will create the CNN model to classify the MNIST with visualizing tool of Visdom\r\n",
    "\r\n",
    "Reference From\r\n",
    "\r\n",
    "https://github.com/deeplearningzerotoall/PyTorch/blob/master/lab-10_3_2_MNIST-CNN%20with%20Visdom.ipynb"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "import torchvision.datasets as datasets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import torch.nn.init as init\r\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Visdom"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import visdom\r\n",
    "\r\n",
    "vis = visdom.Visdom()\r\n",
    "vis.close(env = \"main\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define loss_tracker"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def loss_tracker(loss_plot, loss_value, num):\r\n",
    "    #num, loss_value are Tensor\r\n",
    "    vis.line(X = num, Y=loss_value, win=loss_plot, update='append')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "\r\n",
    "torch.manual_seed(1)\r\n",
    "\r\n",
    "if device == 'cuda':\r\n",
    "    torch.cuda.manual_seed_all(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set Hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "learning_rate = 0.001\r\n",
    "training_epochs = 15\r\n",
    "batch_size = 32"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load MNIST Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "mnist_train = datasets.MNIST(download = True,\r\n",
    "                             train = True,\r\n",
    "                             transform = transforms.ToTensor(),\r\n",
    "                             root = 'MNIST_data/')\r\n",
    "mnist_test = datasets.MNIST(root = 'MNIST_data/',\r\n",
    "                            train = False,\r\n",
    "                            download = True,\r\n",
    "                            transform = transforms.ToTensor())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset = mnist_train, shuffle = True, drop_last = True, batch_size = batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class CNN(nn.Module):\r\n",
    "\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.layer1 = nn.Sequential(\r\n",
    "            nn.Conv2d(1, 32, kernel_size = 3, stride = 1, padding = 1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2)\r\n",
    "        )\r\n",
    "        self.layer2 = nn.Sequential(\r\n",
    "            nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2)\r\n",
    "        )\r\n",
    "        self.layer3 = nn.Sequential(\r\n",
    "            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2)\r\n",
    "        )\r\n",
    "        \r\n",
    "        self.fc1 = nn.Linear(3 * 3 * 128, 625)\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        self.fc2 = nn.Linear(625, 10, bias = True)\r\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\r\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = self.layer1(x)\r\n",
    "        out = self.layer2(out)\r\n",
    "        out = self.layer3(out)\r\n",
    "        #print(out.shape) torch.Size([1, 128, 3, 3])\r\n",
    "        out = out.view(out.size(0), -1)\r\n",
    "        #print(out.shape) torch.Size([1, 1152])\r\n",
    "        out = self.fc1(out)\r\n",
    "        out = self.relu(out)\r\n",
    "        out = self.fc2(out)\r\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model = CNN().to(device)\r\n",
    "\r\n",
    "value = torch.Tensor(1,1,28,28).to(device)\r\n",
    "print(model(value).shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make Plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "loss_plt = vis.line(Y = torch.Tensor(1).zero_(), opts = dict(title = 'loss_tracker', legend=['loss'], showlegend = True))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train with loss_tracker"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "total_batch = len(data_loader)\r\n",
    "\r\n",
    "for epoch in range(training_epochs):\r\n",
    "    avg_cost = 0\r\n",
    "\r\n",
    "    for X, Y in data_loader:\r\n",
    "\r\n",
    "        X = X.to(device)\r\n",
    "        Y = Y.to(device)\r\n",
    "\r\n",
    "        #prediction\r\n",
    "        pred = model(X)\r\n",
    "\r\n",
    "        #cost\r\n",
    "        cost = F.cross_entropy(pred, Y)\r\n",
    "\r\n",
    "        #Reduce the cost\r\n",
    "        optimizer.zero_grad()\r\n",
    "        cost.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        avg_cost += cost\r\n",
    "\r\n",
    "    avg_cost = avg_cost / total_batch\r\n",
    "\r\n",
    "    print('Epoch: {} / {}, Cost: {:.6f}'.format(epoch+1, training_epochs, avg_cost))\r\n",
    "    loss_tracker(loss_plt, torch.Tensor([avg_cost]), torch.Tensor([epoch]))\r\n",
    "print('Learning Finished')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1 / 15, Cost: 0.116303\n",
      "Epoch: 2 / 15, Cost: 0.040117\n",
      "Epoch: 3 / 15, Cost: 0.028779\n",
      "Epoch: 4 / 15, Cost: 0.021760\n",
      "Epoch: 5 / 15, Cost: 0.017429\n",
      "Epoch: 6 / 15, Cost: 0.014483\n",
      "Epoch: 7 / 15, Cost: 0.012259\n",
      "Epoch: 8 / 15, Cost: 0.010881\n",
      "Epoch: 9 / 15, Cost: 0.010224\n",
      "Epoch: 10 / 15, Cost: 0.007701\n",
      "Epoch: 11 / 15, Cost: 0.009009\n",
      "Epoch: 12 / 15, Cost: 0.006754\n",
      "Epoch: 13 / 15, Cost: 0.007524\n",
      "Epoch: 14 / 15, Cost: 0.007479\n",
      "Epoch: 15 / 15, Cost: 0.005707\n",
      "Learning Finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./imgs/plot1.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "with torch.no_grad():\r\n",
    "    print(mnist_test.data.shape)\r\n",
    "    print(mnist_test.data[0].dtype)\r\n",
    "    X_test = mnist_test.data.view(len(mnist_test), 1, 28, 28).float().to(device)#if not .float() error : RuntimeError: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same\r\n",
    "    print(X_test.shape)\r\n",
    "    print(X_test[0].dtype)\r\n",
    "    Y_test = mnist_test.targets.to(device)\r\n",
    "\r\n",
    "    pred = model(X_test).to(device)\r\n",
    "    correct_prediction = (torch.argmax(pred, 1) == Y_test)\r\n",
    "    accuracy = correct_prediction.float().mean()\r\n",
    "\r\n",
    "    r = random.randint(0, len(X_test.data) - 1)\r\n",
    "    X_single_prediction = X_test[r:r+1]\r\n",
    "    Y_single_prediction = Y_test[r:r+1]\r\n",
    "    print(X_single_prediction.shape) # if [r] => torch.size([1, 28, 28]) # if [r:r+1] => torch.size([1,1,28,28])\r\n",
    "    \r\n",
    "    print('Accuracy: {:.9f}'.format(accuracy.item()))\r\n",
    "    print('Prediction: {}, Label: {}'.format(torch.argmax(model(X_single_prediction)), Y_single_prediction.item()))\r\n",
    "\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([10000, 28, 28])\n",
      "torch.uint8\n",
      "torch.Size([10000, 1, 28, 28])\n",
      "torch.float32\n",
      "torch.Size([1, 1, 28, 28])\n",
      "Accuracy: 0.949599981\n",
      "Prediction: 0, Label: 0\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('buddhalight': conda)"
  },
  "interpreter": {
   "hash": "38ed4d61829b01de31b0fe0651719916120d9f7e023a62cbbfea93b7d24a50a0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}